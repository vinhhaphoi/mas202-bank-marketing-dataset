import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import LabelEncoder, StandardScaler
import warnings
from datetime import datetime
import os

try:
    from docx import Document
    from docx.shared import Pt, RGBColor
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False

try:
    from reportlab.lib.pagesizes import letter
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import inch
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
    from reportlab.lib.enums import TA_LEFT, TA_CENTER
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False

warnings.filterwarnings('ignore')

class BankMarketingAnalysis:
    def __init__(self, filepath):
        """Kh·ªüi t·∫°o ph√¢n t√≠ch v·ªõi d·ªØ li·ªáu t·ª´ file CSV"""
        self.df = pd.read_csv(filepath)
        self.report = []
        self.analysis_history = []
        self.insights = []
        self.visualizations = []
        
        # T·∫°o th∆∞ m·ª•c output
        self.output_dir = 'analysis_output'
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
        
        # C·∫•u h√¨nh pandas ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß
        pd.set_option('display.max_columns', None)
        pd.set_option('display.width', None)
        pd.set_option('display.max_colwidth', None)
        pd.set_option('display.expand_frame_repr', False)
        
        # C·∫•u h√¨nh matplotlib
        plt.style.use('seaborn-v0_8-darkgrid')
        sns.set_palette("husl")
        
        # Kh·ªüi t·∫°o m√¥ t·∫£ bi·∫øn
        self._init_variable_descriptions()
        
        self.setup_data()

    def _init_variable_descriptions(self):
        """Kh·ªüi t·∫°o m√¥ t·∫£ c√°c bi·∫øn ƒë·ªÉ d√πng trong b√°o c√°o v√† ch√∫ th√≠ch bi·ªÉu ƒë·ªì"""
        # C√°c m√¥ t·∫£ m·∫´u cho c√°c bi·∫øn th∆∞·ªùng g·∫∑p (b·ªï sung khi c·∫ßn)
        self.var_desc = {
            'age': 'Tu·ªïi c·ªßa kh√°ch h√†ng',
            'balance': 'S·ªë d∆∞ t√†i kho·∫£n (ƒë∆°n v·ªã ti·ªÅn t·ªá)',
            'day': 'Ng√†y trong th√°ng khi li√™n h·ªá',
            'duration': 'Th·ªùi l∆∞·ª£ng cu·ªôc g·ªçi (gi√¢y)',
            'campaign': 'S·ªë l·∫ßn li√™n h·ªá trong chi·∫øn d·ªãch hi·ªán t·∫°i',
            'pdays': 'S·ªë ng√†y k·ªÉ t·ª´ l·∫ßn li√™n h·ªá tr∆∞·ªõc (-1 n·∫øu ch∆∞a t·ª´ng li√™n h·ªá)',
            'previous': 'S·ªë l·∫ßn li√™n h·ªá tr∆∞·ªõc ƒë√≥',
            'job': 'Ngh·ªÅ nghi·ªáp c·ªßa kh√°ch h√†ng',
            'marital': 'T√¨nh tr·∫°ng h√¥n nh√¢n',
            'deposit': 'Kh√°ch h√†ng g·ª≠i ti·ªÅn ti·∫øt ki·ªám hay kh√¥ng (yes/no)'
        }
        # Th√™m m√¥ t·∫£ cho m·ªçi c·ªôt c√≤n l·∫°i d∆∞·ªõi d·∫°ng chung
        for col in self.df.columns:
            if col not in self.var_desc:
                self.var_desc[col] = f'M√¥ t·∫£ ch∆∞a c√≥ cho bi·∫øn "{col}"'

    def save_variable_descriptions(self):
        """L∆∞u file m√¥ t·∫£ bi·∫øn (variable_descriptions.txt) v√†o th∆∞ m·ª•c output"""
        filename = f'{self.output_dir}/variable_descriptions.txt'
        lines = ["M√î T·∫¢ C√ÅC BI·∫æN (Ti·∫øng Vi·ªát):", "="*60]
        for col, desc in self.var_desc.items():
            lines.append(f"{col}: {desc}")
        with open(filename, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        self.report.append(f"\n‚úì M√¥ t·∫£ bi·∫øn ƒë∆∞·ª£c l∆∞u v√†o: {filename}")
        print(f"\n‚úì ƒê√£ l∆∞u m√¥ t·∫£ bi·∫øn: {filename}")
        return filename

    def setup_data(self):
        """Chu·∫©n b·ªã d·ªØ li·ªáu cho ph√¢n t√≠ch"""
        self.le_dict = {}
        self.df_encoded = self.df.copy()
        
        categorical_cols = self.df_encoded.select_dtypes(include=['object']).columns
        for col in categorical_cols:
            le = LabelEncoder()
            self.df_encoded[col] = le.fit_transform(self.df_encoded[col])
            self.le_dict[col] = le
    
    def normalize_data(self):
        """
        T√çNH NƒÇNG: Chu·∫©n H√≥a D·ªØ Li·ªáu
        M√î T·∫¢: Chu·∫©n h√≥a c√°c bi·∫øn ƒë·ªãnh l∆∞·ª£ng b·∫±ng StandardScaler
        - Chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ bi·∫øn s·ªë v·ªÅ thang ƒëo [trung b√¨nh=0, ƒë·ªô l·ªách chu·∫©n=1]
        - Gi√∫p c√°c thu·∫≠t to√°n h·ªçc m√°y ho·∫°t ƒë·ªông t·ªët h∆°n
        - L∆∞u b·ªô chu·∫©n h√≥a ƒë·ªÉ chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu m·ªõi
        """
        print("\n" + "="*80)
        print("CHU·∫®N H√ìA D·ªÆ LI·ªÜU")
        print("="*80)
        
        # 1. L·∫•y c√°c bi·∫øn s·ªë
        numerical_cols = list(self.df.select_dtypes(include=[np.number]).columns)
        
        print(f"\n‚úì Ph√°t hi·ªán {len(numerical_cols)} bi·∫øn s·ªë c·∫ßn chu·∫©n h√≥a:")
        print(f"  {numerical_cols}")
        
        # 2. Th·ªëng k√™ TR∆Ø·ªöC chu·∫©n h√≥a
        print("\n" + "="*80)
        print("TR∆Ø·ªöC CHU·∫®N H√ìA")
        print("="*80)
        stats_before = self.df[numerical_cols].describe()
        print("\nTh·ªëng k√™ m√¥ t·∫£:")
        print(stats_before)
        
        self.report.append("\n" + "="*80)
        self.report.append("CHU·∫®N H√ìA D·ªÆ LI·ªÜU")
        self.report.append("="*80)
        self.report.append("\n" + "="*80)
        self.report.append("TR∆Ø·ªöC CHU·∫®N H√ìA")
        self.report.append("="*80)
        self.report.append("\nTh·ªëng k√™ m√¥ t·∫£:")
        self.report.append(str(stats_before))
        
        # 3. √Åp d·ª•ng StandardScaler
        scaler = StandardScaler()
        self.df_normalized = self.df.copy()
        self.df_normalized[numerical_cols] = scaler.fit_transform(self.df[numerical_cols])
        self.scaler = scaler
        
        print(f"\n‚úì ƒê√£ chu·∫©n h√≥a {len(numerical_cols)} bi·∫øn s·ªë b·∫±ng StandardScaler")
        
        # 4. Th·ªëng k√™ SAU chu·∫©n h√≥a
        print("\n" + "="*80)
        print("SAU CHU·∫®N H√ìA")
        print("="*80)
        stats_after = self.df_normalized[numerical_cols].describe()
        print("\nTh·ªëng k√™ m√¥ t·∫£:")
        print(stats_after)
        
        self.report.append("\n" + "="*80)
        self.report.append("SAU CHU·∫®N H√ìA")
        self.report.append("="*80)
        self.report.append("\nTh·ªëng k√™ m√¥ t·∫£:")
        self.report.append(str(stats_after))
        
        # 5. So s√°nh chi ti·∫øt t·ª´ng bi·∫øn
        print("\n" + "="*80)
        print("SO S√ÅNH CHI TI·∫æT")
        print("="*80)
        
        self.report.append("\n" + "="*80)
        self.report.append("SO S√ÅNH CHI TI·∫æT")
        self.report.append("="*80)
        
        comparison_data = []
        for col in numerical_cols:
            before_mean = self.df[col].mean()
            before_std = self.df[col].std()
            before_min = self.df[col].min()
            before_max = self.df[col].max()
            
            after_mean = self.df_normalized[col].mean()
            after_std = self.df_normalized[col].std()
            after_min = self.df_normalized[col].min()
            after_max = self.df_normalized[col].max()
            
            print(f"\n{col}:")
            print(f"  Tr∆∞·ªõc: Trung b√¨nh={before_mean:.4f}, ƒê·ªô l·ªách chu·∫©n={before_std:.4f}, Min={before_min:.4f}, Max={before_max:.4f}")
            print(f"  Sau:   Trung b√¨nh={after_mean:.4f}, ƒê·ªô l·ªách chu·∫©n={after_std:.4f}, Min={after_min:.4f}, Max={after_max:.4f}")
            
            self.report.append(f"\n{col}:")
            self.report.append(f"  Tr∆∞·ªõc: Trung b√¨nh={before_mean:.4f}, ƒê·ªô l·ªách chu·∫©n={before_std:.4f}, Min={before_min:.4f}, Max={before_max:.4f}")
            self.report.append(f"  Sau:   Trung b√¨nh={after_mean:.4f}, ƒê·ªô l·ªách chu·∫©n={after_std:.4f}, Min={after_min:.4f}, Max={after_max:.4f}")
        
        # 6. Th√¥ng tin m√£ h√≥a bi·∫øn ph√¢n lo·∫°i
        print(f"\n‚úì Th√¥ng tin m√£ h√≥a bi·∫øn ph√¢n lo·∫°i:")
        self.report.append(f"\n‚úì Th√¥ng tin m√£ h√≥a bi·∫øn ph√¢n lo·∫°i:")
        
        for col, le in self.le_dict.items():
            print(f"  {col}: {len(le.classes_)} l·ªõp")
            print(f"    √Ånh x·∫°: {dict(zip(le.classes_, le.transform(le.classes_)))}")
            self.report.append(f"  {col}: {len(le.classes_)} l·ªõp")
            self.report.append(f"    √Ånh x·∫°: {dict(zip(le.classes_, le.transform(le.classes_)))}")
        
        self.analysis_history.append("Chu·∫©n H√≥a D·ªØ Li·ªáu")
    
    # ============ A) DESCRIPTIVE STATISTICS ============
    def descriptive_statistics(self):
        """
        T√çNH NƒÇNG: Ph√¢n T√≠ch Th·ªëng K√™ M√¥ T·∫£
        M√î T·∫¢: Cung c·∫•p t√≥m t·∫Øt to√†n di·ªán v·ªÅ t·∫≠p d·ªØ li·ªáu bao g·ªìm:
        - Th√¥ng tin c∆° b·∫£n (s·ªë d√≤ng, s·ªë c·ªôt, t√™n c·ªôt)
        - Ki·ªÉu d·ªØ li·ªáu c·ªßa t·∫•t c·∫£ bi·∫øn
        - Ph√°t hi·ªán gi√° tr·ªã thi·∫øu
        - T√≥m t·∫Øt th·ªëng k√™ cho c√°c bi·∫øn ƒë·ªãnh l∆∞·ª£ng
        - ƒê·∫øm gi√° tr·ªã cho c√°c bi·∫øn ƒë·ªãnh t√≠nh
        """
        print("\n" + "="*80)
        print("A) PH√ÇN T√çCH TH·ªêNG K√ä M√î T·∫¢")
        print("="*80)
        
        self.report.append("\n" + "="*80)
        self.report.append("A) PH√ÇN T√çCH TH·ªêNG K√ä M√î T·∫¢")
        self.report.append("="*80)
        
        # 1. Basic information
        print("\n1. TH√îNG TIN C∆† B·∫¢N")
        self.report.append("\n1. TH√îNG TIN C∆† B·∫¢N")
        print(f"   - S·ªë d√≤ng: {self.df.shape[0]}")
        print(f"   - S·ªë c·ªôt: {self.df.shape[1]}")
        print(f"   - T√™n c·ªôt: {list(self.df.columns)}")
        self.report.append(f"   - S·ªë d√≤ng: {self.df.shape[0]}")
        self.report.append(f"   - S·ªë c·ªôt: {self.df.shape[1]}")
        
        # 2. Data types
        print("\n2. KI·ªÇU D·ªÆ LI·ªÜU")
        self.report.append("\n2. KI·ªÇU D·ªÆ LI·ªÜU")
        print(self.df.dtypes)
        self.report.append(str(self.df.dtypes))
        
        # 3. Missing values
        print("\n3. KI·ªÇM TRA GI√Å TR·ªä THI·∫æU")
        self.report.append("\n3. KI·ªÇM TRA GI√Å TR·ªä THI·∫æU")
        missing = self.df.isnull().sum()
        if missing.sum() == 0:
            print("   - Kh√¥ng ph√°t hi·ªán gi√° tr·ªã thi·∫øu")
            self.report.append("   - Kh√¥ng ph√°t hi·ªán gi√° tr·ªã thi·∫øu")
        else:
            print(missing[missing > 0])
            self.report.append(str(missing[missing > 0]))
        
        # 4. Numerical statistics
        print("\n4. TH·ªêNG K√ä BI·∫æN ƒê·ªäNH L∆Ø·ª¢NG")
        self.report.append("\n4. TH·ªêNG K√ä BI·∫æN ƒê·ªäNH L∆Ø·ª¢NG")
        numerical_cols = self.df.select_dtypes(include=[np.number]).columns
        stats_df = self.df[numerical_cols].describe()
        
        # In t·ª´ng c·ªôt m·ªôt c√°ch r√µ r√†ng ƒë·ªÉ ƒë·∫£m b·∫£o hi·ªÉn th·ªã ƒë·∫ßy ƒë·ªß
        print(f"\nT·ªïng s·ªë bi·∫øn ƒë·ªãnh l∆∞·ª£ng: {len(numerical_cols)}")
        print(f"Danh s√°ch bi·∫øn: {list(numerical_cols)}\n")
        
        # Hi·ªÉn th·ªã to√†n b·ªô ma tr·∫≠n th·ªëng k√™
        with pd.option_context('display.max_columns', None, 
                              'display.width', 200,
                              'display.precision', 6):
            print(stats_df)
        
        self.report.append(f"\nT·ªïng s·ªë bi·∫øn ƒë·ªãnh l∆∞·ª£ng: {len(numerical_cols)}")
        self.report.append(f"Danh s√°ch bi·∫øn: {list(numerical_cols)}")
        self.report.append("\n" + str(stats_df))
        
        # 5. Categorical statistics
        print("\n5. TH·ªêNG K√ä BI·∫æN ƒê·ªäNH T√çNH")
        self.report.append("\n5. TH·ªêNG K√ä BI·∫æN ƒê·ªäNH T√çNH")
        categorical_cols = self.df.select_dtypes(include=['object']).columns
        for col in categorical_cols:
            print(f"\n   {col}:")
            print(self.df[col].value_counts())
            self.report.append(f"\n   {col}:")
            self.report.append(str(self.df[col].value_counts()))
        
        self.analysis_history.append("Ph√¢n T√≠ch Th·ªëng K√™ M√¥ T·∫£")
    
    # ============ B) ESTIMATION & HYPOTHESIS TESTING ============
    def estimation_hypothesis_testing(self):
        """
        T√çNH NƒÇNG: ∆Ø·ªõc L∆∞·ª£ng v√† Ki·ªÉm ƒê·ªãnh Gi·∫£ Thuy·∫øt
        M√î T·∫¢: Th·ª±c hi·ªán suy di·ªÖn th·ªëng k√™ bao g·ªìm:
        - Kho·∫£ng tin c·∫≠y 95%
        - Ki·ªÉm ƒë·ªãnh T
        - Ki·ªÉm ƒë·ªãnh Chi-b√¨nh ph∆∞∆°ng
        - Gi·∫£i th√≠ch gi√° tr·ªã P
        """
        print("\n" + "="*80)
        print("B) ∆Ø·ªöC L∆Ø·ª¢NG V√Ä KI·ªÇM ƒê·ªäNH GI·∫¢ THUY·∫æT")
        print("="*80)
        
        self.report.append("\n" + "="*80)
        self.report.append("B) ∆Ø·ªöC L∆Ø·ª¢NG V√Ä KI·ªÇM ƒê·ªäNH GI·∫¢ THUY·∫æT")
        self.report.append("="*80)
        
        numerical_cols = self.df.select_dtypes(include=[np.number]).columns
        
        # 1. Confidence intervals for means
        print("\n1. KHO·∫¢NG TIN C·∫¨Y 95% CHO TRUNG B√åNH")
        self.report.append("\n1. KHO·∫¢NG TIN C·∫¨Y 95% CHO TRUNG B√åNH")
        for col in numerical_cols:
            data = self.df[col].dropna()
            mean = data.mean()
            std = data.std()
            n = len(data)
            se = std / np.sqrt(n)
            ci = stats.t.interval(0.95, n-1, loc=mean, scale=se)
            print(f"\n   {col}:")
            print(f"      Trung b√¨nh: {mean:.4f}")
            print(f"      Kho·∫£ng tin c·∫≠y 95%: [{ci[0]:.4f}, {ci[1]:.4f}]")
            self.report.append(f"\n   {col}: Trung b√¨nh={mean:.4f}, Kho·∫£ng tin c·∫≠y=[{ci[0]:.4f}, {ci[1]:.4f}]")
        
        # 2. T-test: age by deposit status
        print("\n2. KI·ªÇM ƒê·ªäNH T: TU·ªîI THEO TR·∫†NG TH√ÅI G·ª¨I TI·ªÄN")
        self.report.append("\n2. KI·ªÇM ƒê·ªäNH T: TU·ªîI THEO TR·∫†NG TH√ÅI G·ª¨I TI·ªÄN")
        if 'deposit' in self.df.columns and 'age' in self.df.columns:
            yes_group = self.df[self.df['deposit'] == 'yes']['age']
            no_group = self.df[self.df['deposit'] == 'no']['age']
            t_stat, p_value = stats.ttest_ind(yes_group, no_group)
            print(f"   Nh√≥m C√≥ (n={len(yes_group)}): Trung b√¨nh={yes_group.mean():.4f}, ƒê·ªô l·ªách chu·∫©n={yes_group.std():.4f}")
            print(f"   Nh√≥m Kh√¥ng (n={len(no_group)}): Trung b√¨nh={no_group.mean():.4f}, ƒê·ªô l·ªách chu·∫©n={no_group.std():.4f}")
            print(f"   Th·ªëng k√™ T: {t_stat:.4f}")
            print(f"   Gi√° tr·ªã P: {p_value:.6f}")
            sig = "C√≥ √Ω nghƒ©a th·ªëng k√™" if p_value < 0.05 else "Kh√¥ng c√≥ √Ω nghƒ©a th·ªëng k√™"
            print(f"   K·∫øt lu·∫≠n: {sig}")
            self.report.append(f"   Th·ªëng k√™ T={t_stat:.4f}, Gi√° tr·ªã P={p_value:.6f}")
        
        # 3. Chi-square test
        print("\n3. KI·ªÇM ƒê·ªäNH CHI-B√åNH PH∆Ø∆†NG: C√îNG VI·ªÜC vs G·ª¨I TI·ªÄN")
        self.report.append("\n3. KI·ªÇM ƒê·ªäNH CHI-B√åNH PH∆Ø∆†NG: C√îNG VI·ªÜC vs G·ª¨I TI·ªÄN")
        if 'job' in self.df.columns and 'deposit' in self.df.columns:
            ct = pd.crosstab(self.df['job'], self.df['deposit'])
            chi2, p_value, dof, expected = stats.chi2_contingency(ct)
            print(f"   Chi-b√¨nh ph∆∞∆°ng: {chi2:.4f}")
            print(f"   Gi√° tr·ªã P: {p_value:.6f}")
            print(f"   B·∫≠c t·ª± do: {dof}")
            sig = "C√≥ s·ª± li√™n k·∫øt" if p_value < 0.05 else "Kh√¥ng c√≥ s·ª± li√™n k·∫øt"
            print(f"   K·∫øt lu·∫≠n: {sig}")
            self.report.append(f"   Chi-b√¨nh ph∆∞∆°ng={chi2:.4f}, Gi√° tr·ªã P={p_value:.6f}")
        
        self.analysis_history.append("∆Ø·ªõc L∆∞·ª£ng & Ki·ªÉm ƒê·ªãnh Gi·∫£ Thuy·∫øt")
    
    # ============ C) CORRELATION ANALYSIS ============
    def correlation_analysis(self):
        """
        T√çNH NƒÇNG: Ph√¢n T√≠ch T∆∞∆°ng Quan
        M√î T·∫¢: Ki·ªÉm tra c√°c m·ªëi quan h·ªá bao g·ªìm:
        - Ma tr·∫≠n t∆∞∆°ng quan Pearson
        - T∆∞∆°ng quan v·ªõi bi·∫øn m·ª•c ti√™u
        - T∆∞∆°ng quan h·∫°ng Spearman
        """
        print("\n" + "="*80)
        print("C) PH√ÇN T√çCH T∆Ø∆†NG QUAN")
        print("="*80)
        
        self.report.append("\n" + "="*80)
        self.report.append("C) PH√ÇN T√çCH T∆Ø∆†NG QUAN")
        self.report.append("="*80)
        
        numerical_cols = self.df_encoded.select_dtypes(include=[np.number]).columns
        
        # 1. Pearson correlation
        print("\n1. MA TR·∫¨N T∆Ø∆†NG QUAN PEARSON")
        self.report.append("\n1. MA TR·∫¨N T∆Ø∆†NG QUAN PEARSON")
        corr_matrix = self.df_encoded[numerical_cols].corr()
        print(corr_matrix)
        self.report.append("\n" + str(corr_matrix))
        
        # 2. Correlation with target variable (deposit)
        if 'deposit' in self.df_encoded.columns:
            print("\n2. T∆Ø∆†NG QUAN V·ªöI BI·∫æN M·ª§C TI√äU (G·ª¨I TI·ªÄN)")
            self.report.append("\n2. T∆Ø∆†NG QUAN V·ªöI BI·∫æN M·ª§C TI√äU (G·ª¨I TI·ªÄN)")
            deposit_corr = corr_matrix['deposit'].sort_values(ascending=False)
            print(deposit_corr)
            self.report.append("\n" + str(deposit_corr))
        
        # 3. Spearman correlation for age vs balance
        print("\n3. T∆Ø∆†NG QUAN H·∫†NG SPEARMAN: TU·ªîI vs S·ªê D∆Ø")
        self.report.append("\n3. T∆Ø∆†NG QUAN H·∫†NG SPEARMAN: TU·ªîI vs S·ªê D∆Ø")
        if 'age' in self.df.columns and 'balance' in self.df.columns:
            spearman_corr, p_value = stats.spearmanr(self.df['age'], self.df['balance'])
            print(f"   H·ªá s·ªë t∆∞∆°ng quan: {spearman_corr:.4f}")
            print(f"   Gi√° tr·ªã P: {p_value:.6f}")
            self.report.append(f"   H·ªá s·ªë t∆∞∆°ng quan: {spearman_corr:.4f}, Gi√° tr·ªã P={p_value:.6f}")
        
        self.analysis_history.append("Ph√¢n T√≠ch T∆∞∆°ng Quan")
    
    # ============ D) ANOVA ANALYSIS ============
    def anova_analysis(self):
        """
        T√çNH NƒÇNG: Ph√¢n T√≠ch ANOVA
        M√î T·∫¢: Ki·ªÉm tra s·ª± kh√°c bi·ªát gi·ªØa c√°c nh√≥m:
        - ANOVA m·ªôt chi·ªÅu: Tu·ªïi theo c√¥ng vi·ªác
        - ANOVA m·ªôt chi·ªÅu: S·ªë d∆∞ theo t√¨nh tr·∫°ng h√¥n nh√¢n
        - Th·ªëng k√™ F v√† gi√° tr·ªã P
        """
        print("\n" + "="*80)
        print("D) PH√ÇN T√çCH ANOVA")
        print("="*80)
        
        self.report.append("\n" + "="*80)
        self.report.append("D) PH√ÇN T√çCH ANOVA")
        self.report.append("="*80)
        
        # 1. One-way ANOVA: Age by job
        print("\n1. ANOVA M·ªòT CHI·ªÄU: TU·ªîI THEO LO·∫†I C√îNG VI·ªÜC")
        self.report.append("\n1. ANOVA M·ªòT CHI·ªÄU: TU·ªîI THEO LO·∫†I C√îNG VI·ªÜC")
        if 'age' in self.df.columns and 'job' in self.df.columns:
            groups = self.df.groupby('job')['age'].apply(list)
            f_stat, p_value = stats.f_oneway(*groups)
            print(f"   Th·ªëng k√™ F: {f_stat:.4f}")
            print(f"   Gi√° tr·ªã P: {p_value:.6f}")
            sig = "C√≥ s·ª± kh√°c bi·ªát ƒë√°ng k·ªÉ" if p_value < 0.05 else "Kh√¥ng c√≥ s·ª± kh√°c bi·ªát ƒë√°ng k·ªÉ"
            print(f"   K·∫øt lu·∫≠n: {sig}")
            self.report.append(f"   Th·ªëng k√™ F={f_stat:.4f}, Gi√° tr·ªã P={p_value:.6f}")
            
            print("\n   Trung b√¨nh tu·ªïi theo lo·∫°i c√¥ng vi·ªác:")
            self.report.append("\n   Trung b√¨nh tu·ªïi theo lo·∫°i c√¥ng vi·ªác:")
            job_means = self.df.groupby('job')['age'].mean().sort_values(ascending=False)
            print(job_means)
            self.report.append("\n" + str(job_means))
        
        # 2. One-way ANOVA: Balance by marital status
        print("\n2. ANOVA M·ªòT CHI·ªÄU: S·ªê D∆Ø THEO T√åNH TR·∫†NG H√îN NH√ÇN")
        self.report.append("\n2. ANOVA M·ªòT CHI·ªÄU: S·ªê D∆Ø THEO T√åNH TR·∫†NG H√îN NH√ÇN")
        if 'balance' in self.df.columns and 'marital' in self.df.columns:
            groups = self.df.groupby('marital')['balance'].apply(list)
            f_stat, p_value = stats.f_oneway(*groups)
            print(f"   Th·ªëng k√™ F: {f_stat:.4f}")
            print(f"   Gi√° tr·ªã P: {p_value:.6f}")
            self.report.append(f"   Th·ªëng k√™ F={f_stat:.4f}, Gi√° tr·ªã P={p_value:.6f}")
        
        self.analysis_history.append("Ph√¢n T√≠ch ANOVA")
    
    # ============ E) REGRESSION ANALYSIS ============
    def regression_analysis(self):
        """
        T√çNH NƒÇNG: Ph√¢n T√≠ch H·ªìi Quy
        M√î T·∫¢: M√¥ h√¨nh h√≥a c√°c m·ªëi quan h·ªá bao g·ªìm:
        - H·ªìi quy tuy·∫øn t√≠nh ƒë∆°n
        - H·ªìi quy tuy·∫øn t√≠nh ƒëa bi·∫øn
        - Gi√° tr·ªã R b√¨nh ph∆∞∆°ng
        """
        print("\n" + "="*80)
        print("E) PH√ÇN T√çCH H·ªíI QUY")
        print("="*80)
        
        self.report.append("\n" + "="*80)
        self.report.append("E) PH√ÇN T√çCH H·ªíI QUY")
        self.report.append("="*80)
        
        numerical_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numerical_cols) >= 2:
            # 1. Simple linear regression: balance vs age
            print("\n1. H·ªíI QUY TUY·∫æN T√çNH ƒê∆†N: S·ªê D∆Ø vs TU·ªîI")
            self.report.append("\n1. H·ªíI QUY TUY·∫æN T√çNH ƒê∆†N: S·ªê D∆Ø vs TU·ªîI")
            if 'age' in self.df.columns and 'balance' in self.df.columns:
                X_simple = self.df[['age']].values
                y_simple = self.df['balance'].values
                model_simple = LinearRegression()
                model_simple.fit(X_simple, y_simple)
                r2_simple = model_simple.score(X_simple, y_simple)
                
                print(f"   H·ªá s·ªë ch·∫∑n: {model_simple.intercept_:.4f}")
                print(f"   H·ªá s·ªë (tu·ªïi): {model_simple.coef_[0]:.4f}")
                print(f"   R b√¨nh ph∆∞∆°ng: {r2_simple:.4f}")
                print(f"   Ph∆∞∆°ng tr√¨nh: S·ªë d∆∞ = {model_simple.intercept_:.4f} + {model_simple.coef_[0]:.4f} * Tu·ªïi")
                self.report.append(f"   H·ªá s·ªë ch·∫∑n={model_simple.intercept_:.4f}")
                self.report.append(f"   H·ªá s·ªë={model_simple.coef_[0]:.4f}")
                self.report.append(f"   R b√¨nh ph∆∞∆°ng={r2_simple:.4f}")
            
            # 2. Multiple linear regression
            print("\n2. H·ªíI QUY TUY·∫æN T√çNH ƒêA BI·∫æN")
            self.report.append("\n2. H·ªíI QUY TUY·∫æN T√çNH ƒêA BI·∫æN")
            selected_cols = [col for col in numerical_cols if col != 'balance'][:5]
            if 'balance' in numerical_cols and len(selected_cols) > 0:
                X_multi = self.df[selected_cols].values
                y_multi = self.df['balance'].values
                model_multi = LinearRegression()
                model_multi.fit(X_multi, y_multi)
                r2_multi = model_multi.score(X_multi, y_multi)
                
                print(f"   Bi·∫øn ƒë·ªôc l·∫≠p: {selected_cols}")
                print(f"   H·ªá s·ªë ch·∫∑n: {model_multi.intercept_:.4f}")
                print(f"   C√°c h·ªá s·ªë:")
                for i, col in enumerate(selected_cols):
                    print(f"      {col}: {model_multi.coef_[i]:.4f}")
                print(f"   R b√¨nh ph∆∞∆°ng: {r2_multi:.4f}")
                self.report.append(f"   Bi·∫øn ƒë·ªôc l·∫≠p: {selected_cols}")
                self.report.append(f"   H·ªá s·ªë ch·∫∑n: {model_multi.intercept_:.4f}")
                self.report.append(f"   R b√¨nh ph∆∞∆°ng: {r2_multi:.4f}")
        
        self.analysis_history.append("Ph√¢n T√≠ch H·ªìi Quy")
    
    def find_insights(self):
        """
        T√çNH NƒÇNG: T·ª± ƒê·ªông T√¨m Insights
        M√î T·∫¢: Ph√°t hi·ªán c√°c patterns v√† insights quan tr·ªçng t·ª´ d·ªØ li·ªáu
        """
        print("\n" + "="*80)
        print("F) T·ª∞ ƒê·ªòNG T√åM INSIGHTS")
        print("="*80)
        
        self.report.append("\n" + "="*80)
        self.report.append("F) T·ª∞ ƒê·ªòNG T√åM INSIGHTS")
        self.report.append("="*80)
        
        insights = []
        
        # 1. Ph√°t hi·ªán outliers
        print("\n1. PH√ÅT HI·ªÜN OUTLIERS (Gi√° tr·ªã ngo·∫°i lai)")
        self.report.append("\n1. PH√ÅT HI·ªÜN OUTLIERS (Gi√° tr·ªã ngo·∫°i lai)")
        numerical_cols = self.df.select_dtypes(include=[np.number]).columns
        
        for col in numerical_cols:
            Q1 = self.df[col].quantile(0.25)
            Q3 = self.df[col].quantile(0.75)
            IQR = Q3 - Q1
            outliers = self.df[(self.df[col] < Q1 - 1.5*IQR) | (self.df[col] > Q3 + 1.5*IQR)]
            
            if len(outliers) > 0:
                pct = (len(outliers) / len(self.df)) * 100
                insight = f"   - {col}: {len(outliers)} outliers ({pct:.2f}%)"
                print(insight)
                self.report.append(insight)
                insights.append(f"Ph√°t hi·ªán {len(outliers)} outliers trong {col}")
        
        # 2. T∆∞∆°ng quan m·∫°nh nh·∫•t
        print("\n2. C√ÅC T∆Ø∆†NG QUAN M·∫†NH NH·∫§T")
        self.report.append("\n2. C√ÅC T∆Ø∆†NG QUAN M·∫†NH NH·∫§T")
        
        if hasattr(self, 'df_encoded'):
            corr_matrix = self.df_encoded.select_dtypes(include=[np.number]).corr()
            corr_pairs = []
            
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    col1 = corr_matrix.columns[i]
                    col2 = corr_matrix.columns[j]
                    corr_val = corr_matrix.iloc[i, j]
                    
                    if abs(corr_val) > 0.5:
                        corr_pairs.append((col1, col2, corr_val))
            
            corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)
            
            for col1, col2, corr_val in corr_pairs[:5]:
                direction = "d∆∞∆°ng" if corr_val > 0 else "√¢m"
                insight = f"   - {col1} ‚Üî {col2}: r={corr_val:.4f} (T∆∞∆°ng quan {direction} m·∫°nh)"
                print(insight)
                self.report.append(insight)
                insights.append(f"T∆∞∆°ng quan m·∫°nh gi·ªØa {col1} v√† {col2}: {corr_val:.4f}")
        
        # 3. Ph√¢n ph·ªëi kh√¥ng chu·∫©n
        print("\n3. KI·ªÇM TRA PH√ÇN PH·ªêI CHU·∫®N")
        self.report.append("\n3. KI·ªÇM TRA PH√ÇN PH·ªêI CHU·∫®N")
        
        for col in numerical_cols:
            if len(self.df[col]) > 3:
                skewness = stats.skew(self.df[col].dropna())
                kurtosis = stats.kurtosis(self.df[col].dropna())
                
                if abs(skewness) > 1:
                    skew_type = "l·ªách ph·∫£i" if skewness > 0 else "l·ªách tr√°i"
                    insight = f"   - {col}: Skewness={skewness:.4f} ({skew_type} m·∫°nh)"
                    print(insight)
                    self.report.append(insight)
                    insights.append(f"{col} c√≥ ph√¢n ph·ªëi {skew_type}")
        
        # 4. Nh√≥m c√≥ trung b√¨nh kh√°c bi·ªát l·ªõn
        if 'deposit' in self.df.columns:
            print("\n4. SO S√ÅNH THEO NH√ìM DEPOSIT")
            self.report.append("\n4. SO S√ÅNH THEO NH√ìM DEPOSIT")
            
            for col in numerical_cols:
                yes_mean = self.df[self.df['deposit'] == 'yes'][col].mean()
                no_mean = self.df[self.df['deposit'] == 'no'][col].mean()
                diff_pct = abs((yes_mean - no_mean) / no_mean * 100)
                
                if diff_pct > 20:
                    insight = f"   - {col}: Nh√≥m Yes={yes_mean:.2f}, Nh√≥m No={no_mean:.2f} (Ch√™nh l·ªách {diff_pct:.1f}%)"
                    print(insight)
                    self.report.append(insight)
                    insights.append(f"Ch√™nh l·ªách l·ªõn v·ªÅ {col} gi·ªØa 2 nh√≥m deposit")
        
        # 5. Bi·∫øn c√≥ ·∫£nh h∆∞·ªüng m·∫°nh ƒë·∫øn target
        if 'deposit' in self.df_encoded.columns:
            print("\n5. BI·∫æN ·∫¢NH H∆Ø·ªûNG M·∫†NH ƒê·∫æN DEPOSIT")
            self.report.append("\n5. BI·∫æN ·∫¢NH H∆Ø·ªûNG M·∫†NH ƒê·∫æN DEPOSIT")
            
            deposit_corr = corr_matrix['deposit'].abs().sort_values(ascending=False)
            top_features = deposit_corr[deposit_corr.index != 'deposit'][:5]
            
            for feature, corr_val in top_features.items():
                insight = f"   - {feature}: |r|={corr_val:.4f}"
                print(insight)
                self.report.append(insight)
                insights.append(f"{feature} c√≥ ·∫£nh h∆∞·ªüng m·∫°nh ƒë·∫øn deposit")
        
        self.insights = insights
        self.analysis_history.append("T·ª± ƒê·ªông T√¨m Insights")
        
        # T√≥m t·∫Øt insights
        print(f"\n‚úì T·ªïng c·ªông ph√°t hi·ªán {len(insights)} insights quan tr·ªçng")
        self.report.append(f"\n‚úì T·ªïng c·ªông ph√°t hi·ªán {len(insights)} insights quan tr·ªçng")
    
    def create_visualizations(self):
        """
        T√çNH NƒÇNG: T·∫°o Tr·ª±c Quan H√≥a
        """
        print("\n" + "="*80)
        print("G) T·∫†O TR·ª∞C QUAN H√ìA D·ªÆ LI·ªÜU")
        print("="*80)
        
        self.report.append("\n" + "="*80)
        self.report.append("G) T·∫†O TR·ª∞C QUAN H√ìA D·ªÆ LI·ªÜU")
        self.report.append("="*80)
        
        numerical_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = self.df.select_dtypes(include=['object']).columns.tolist()
        
        # 1. Ph√¢n ph·ªëi c√°c bi·∫øn s·ªë
        print("\n1. ƒêang t·∫°o bi·ªÉu ƒë·ªì ph√¢n ph·ªëi...")
        fig, axes = plt.subplots(3, 3, figsize=(18, 15))
        fig.suptitle('PH√ÇN PH·ªêI C√ÅC BI·∫æN ƒê·ªäNH L∆Ø·ª¢NG', fontsize=16, fontweight='bold')
        
        for idx, col in enumerate(numerical_cols[:9]):
            row = idx // 3
            col_idx = idx % 3
            ax = axes[row, col_idx]
            
            ax.hist(self.df[col].dropna(), bins=30, edgecolor='black', alpha=0.7, color='skyblue')
            ax.set_xlabel(col, fontsize=10)
            ax.set_ylabel('T·∫ßn s·ªë', fontsize=10)
            ax.set_title(f'Ph√¢n ph·ªëi {col}', fontsize=11, fontweight='bold')
            ax.grid(True, alpha=0.3)
        
        # Ch√∫ th√≠ch cho c·∫£ figure: m√¥ t·∫£ bi·∫øn v√† m·ª•c ƒë√≠ch
        caption = "Ghi ch√∫: M·ªói histogram hi·ªÉn th·ªã ph√¢n ph·ªëi gi√° tr·ªã. " \
                  "M·ª•c ƒë√≠ch: Hi·ªÉu h√¨nh d·∫°ng ph√¢n ph·ªëi (l·ªách, ƒëa ƒë·ªânh) v√† gi√∫p ph√°t hi·ªán outliers."
        fig.text(0.5, 0.02, caption, ha='center', fontsize=10)
        
        plt.tight_layout(rect=[0, 0.03, 1, 0.97])
        filename = f'{self.output_dir}/01_phan_phoi_bien_so.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        self.visualizations.append(filename)
        print(f"   ‚úì ƒê√£ l∆∞u: {filename}")
        
        # 2. Boxplot ƒë·ªÉ ph√°t hi·ªán outliers
        print("\n2. ƒêang t·∫°o boxplot ph√°t hi·ªán outliers...")
        fig, axes = plt.subplots(2, 4, figsize=(20, 10))
        fig.suptitle('BOXPLOT - PH√ÅT HI·ªÜN OUTLIERS', fontsize=16, fontweight='bold')
        
        for idx, col in enumerate(numerical_cols[:8]):
            row = idx // 4
            col_idx = idx % 4
            ax = axes[row, col_idx]
            
            ax.boxplot(self.df[col].dropna(), vert=True)
            ax.set_ylabel(col, fontsize=10)
            ax.set_title(f'Boxplot: {col}', fontsize=11, fontweight='bold')
            ax.grid(True, alpha=0.3)
        
        # Ch√∫ th√≠ch cho c·∫£ figure: m√¥ t·∫£ bi·∫øn v√† m·ª•c ƒë√≠ch
        caption = "Ghi ch√∫: Boxplot bi·ªÉu di·ªÖn median, IQR v√† c√°c ƒëi·ªÉm ngo·∫°i lai. " \
                  "M·ª•c ƒë√≠ch: Ph√°t hi·ªán outliers v√† so s√°nh ph√¢n ph·ªëi theo bi·∫øn."
        fig.text(0.5, 0.01, caption, ha='center', fontsize=10)
        plt.tight_layout(rect=[0, 0.03, 1, 0.97])
        filename = f'{self.output_dir}/02_boxplot_outliers.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        self.visualizations.append(filename)
        print(f"   ‚úì ƒê√£ l∆∞u: {filename}")

        # 3. Ma tr·∫≠n t∆∞∆°ng quan (Heatmap)
        if hasattr(self, 'df_encoded'):
            print("\n3. ƒêang t·∫°o ma tr·∫≠n t∆∞∆°ng quan...")
            corr_matrix = self.df_encoded.select_dtypes(include=[np.number]).corr()
            
            plt.figure(figsize=(14, 12))
            sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', 
                       center=0, square=True, linewidths=1, cbar_kws={"shrink": 0.8})
            plt.title('MA TR·∫¨N T∆Ø∆†NG QUAN PEARSON', fontsize=16, fontweight='bold', pad=20)
            plt.tight_layout()
            
            caption = "Ghi ch√∫: Heatmap hi·ªÉn th·ªã h·ªá s·ªë t∆∞∆°ng quan Pearson gi·ªØa c√°c bi·∫øn. " \
                      "M·ª•c ƒë√≠ch: X√°c ƒë·ªãnh c√°c c·∫∑p bi·∫øn c√≥ t∆∞∆°ng quan m·∫°nh (|r| > 0.5) ƒë·ªÉ ph√¢n t√≠ch s√¢u h∆°n."
            plt.gcf().text(0.5, 0.01, caption, ha='center', fontsize=10)
            filename = f'{self.output_dir}/03_ma_tran_tuong_quan.png'
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            plt.close()
            self.visualizations.append(filename)
            print(f"   ‚úì ƒê√£ l∆∞u: {filename}")

        # 4. Scatter plots cho t∆∞∆°ng quan m·∫°nh
        print("\n4. ƒêang t·∫°o scatter plots...")
        if len(numerical_cols) >= 2:
            fig, axes = plt.subplots(2, 3, figsize=(18, 12))
            fig.suptitle('SCATTER PLOTS - M·ªêI QUAN H·ªÜ GI·ªÆA C√ÅC BI·∫æN', fontsize=16, fontweight='bold')
            
            plot_idx = 0
            for i in range(len(numerical_cols)):
                for j in range(i+1, len(numerical_cols)):
                    if plot_idx >= 6:
                        break
                    
                    row = plot_idx // 3
                    col_idx = plot_idx % 3
                    ax = axes[row, col_idx]
                    
                    ax.scatter(self.df[numerical_cols[i]], self.df[numerical_cols[j]], 
                             alpha=0.5, s=20, color='steelblue')
                    ax.set_xlabel(numerical_cols[i], fontsize=10)
                    ax.set_ylabel(numerical_cols[j], fontsize=10)
                    
                    # T√≠nh correlation
                    corr = self.df[numerical_cols[i]].corr(self.df[numerical_cols[j]])
                    ax.set_title(f'{numerical_cols[i]} vs {numerical_cols[j]}\nr={corr:.3f}', 
                               fontsize=11, fontweight='bold')
                    ax.grid(True, alpha=0.3)
                    
                    plot_idx += 1
                    
                if plot_idx >= 6:
                    break
            
            # Ch√∫ th√≠ch cho c·∫£ figure: m√¥ t·∫£ bi·∫øn v√† m·ª•c ƒë√≠ch
            caption = "Ghi ch√∫: Scatter plot hi·ªÉn th·ªã m·ªëi quan h·ªá (tuy·∫øn t√≠nh/kh√¥ng tuy·∫øn t√≠nh) gi·ªØa hai bi·∫øn. " \
                      "M·ª•c ƒë√≠ch: Ki·ªÉm tra xu h∆∞·ªõng v√† m·∫≠t ƒë·ªô ƒëi·ªÉm (c√≥ th·ªÉ k√®m h·ªá s·ªë t∆∞∆°ng quan r)."
            fig.text(0.5, 0.02, caption, ha='center', fontsize=10)
            plt.tight_layout(rect=[0, 0.03, 1, 0.95])
            filename = f'{self.output_dir}/04_scatter_plots.png'
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            plt.close()
            self.visualizations.append(filename)
            print(f"   ‚úì ƒê√£ l∆∞u: {filename}")

        # 5. So s√°nh theo nh√≥m deposit
        if 'deposit' in self.df.columns:
            print("\n5. ƒêang t·∫°o bi·ªÉu ƒë·ªì so s√°nh theo deposit...")
            fig, axes = plt.subplots(2, 3, figsize=(18, 10))
            fig.suptitle('SO S√ÅNH C√ÅC BI·∫æN THEO DEPOSIT (YES/NO)', fontsize=16, fontweight='bold')
            
            for idx, col in enumerate(numerical_cols[:6]):
                row = idx // 3
                col_idx = idx % 3
                ax = axes[row, col_idx]
                
                yes_data = self.df[self.df['deposit'] == 'yes'][col]
                no_data = self.df[self.df['deposit'] == 'no'][col]
                
                ax.boxplot([yes_data, no_data], labels=['Yes', 'No'])
                ax.set_ylabel(col, fontsize=10)
                ax.set_xlabel('Deposit', fontsize=10)
                ax.set_title(f'{col} theo Deposit', fontsize=11, fontweight='bold')
                ax.grid(True, alpha=0.3)
            
            # Ch√∫ th√≠ch cho c·∫£ figure: m√¥ t·∫£ bi·∫øn v√† m·ª•c ƒë√≠ch
            caption = "Ghi ch√∫: So s√°nh ph√¢n ph·ªëi gi·ªØa hai nh√≥m Deposit (Yes/No). " \
                      "M·ª•c ƒë√≠ch: Xem bi·∫øn s·ªë n√†o kh√°c bi·ªát l·ªõn gi·ªØa hai nh√≥m."
            fig.text(0.5, 0.01, caption, ha='center', fontsize=10)
            filename = f'{self.output_dir}/05_so_sanh_theo_deposit.png'
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            plt.close()
            self.visualizations.append(filename)
            print(f"   ‚úì ƒê√£ l∆∞u: {filename}")

        # 6. Bar charts cho bi·∫øn ph√¢n lo·∫°i
        print("\n6. ƒêang t·∫°o bar charts cho bi·∫øn ph√¢n lo·∫°i...")
        if len(categorical_cols) > 0:
            fig, axes = plt.subplots(2, 2, figsize=(16, 10))
            fig.suptitle('PH√ÇN PH·ªêI C√ÅC BI·∫æN PH√ÇN LO·∫†I', fontsize=16, fontweight='bold')
            
            for idx, col in enumerate(categorical_cols[:4]):
                row = idx // 2
                col_idx = idx % 2
                ax = axes[row, col_idx]
                
                value_counts = self.df[col].value_counts()
                value_counts.plot(kind='bar', ax=ax, color='coral', edgecolor='black')
                ax.set_xlabel(col, fontsize=10)
                ax.set_ylabel('S·ªë l∆∞·ª£ng', fontsize=10)
                ax.set_title(f'Ph√¢n ph·ªëi {col}', fontsize=11, fontweight='bold')
                ax.grid(True, alpha=0.3, axis='y')
                plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')
            
            plt.tight_layout()
            filename = f'{self.output_dir}/06_phan_phoi_bien_phan_loai.png'
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            plt.close()
            self.visualizations.append(filename)
            print(f"   ‚úì ƒê√£ l∆∞u: {filename}")
        
        # 7. Pairplot cho top bi·∫øn quan tr·ªçng
        if 'deposit' in self.df.columns and len(numerical_cols) >= 3:
            print("\n7. ƒêang t·∫°o pairplot...")
            top_cols = numerical_cols[:4] + ['deposit']
            df_sample = self.df[top_cols].sample(min(500, len(self.df)), random_state=42)
            
            pairplot = sns.pairplot(df_sample, hue='deposit', diag_kind='kde', 
                                   palette={'yes': 'green', 'no': 'red'}, 
                                   plot_kws={'alpha': 0.6})
            pairplot.fig.suptitle('PAIRPLOT - M·ªêI QUAN H·ªÜ ƒêA BI·∫æN', 
                                 fontsize=16, fontweight='bold', y=1.02)
            
            filename = f'{self.output_dir}/07_pairplot.png'
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            plt.close()
            self.visualizations.append(filename)
            print(f"   ‚úì ƒê√£ l∆∞u: {filename}")
        
        # Sau khi t·∫°o xong, l∆∞u m√¥ t·∫£ bi·∫øn
        self.save_variable_descriptions()
        
        print(f"\n‚úì ƒê√£ t·∫°o {len(self.visualizations)} bi·ªÉu ƒë·ªì")
        self.report.append(f"\n‚úì ƒê√£ t·∫°o {len(self.visualizations)} bi·ªÉu ƒë·ªì trong th∆∞ m·ª•c {self.output_dir}/")
        
        for viz in self.visualizations:
            self.report.append(f"   - {viz}")
        
        self.analysis_history.append("T·∫°o Tr·ª±c Quan H√≥a")
    
    def save_terminal_output(self):
        """L∆∞u to√†n b·ªô output terminal"""
        filename = f'{self.output_dir}/terminal_output.txt'
        with open(filename, 'w', encoding='utf-8') as f:
            f.write('\n'.join(self.report))
        print(f"\n‚úì ƒê√£ l∆∞u terminal output: {filename}")
        return filename
    
    def create_summary_report(self):
        """T·∫°o b√°o c√°o t·ªïng h·ª£p v·ªõi insights v√† visualizations"""
        print("\n" + "="*80)
        print("T·∫†O B√ÅO C√ÅO T·ªîNG H·ª¢P")
        print("="*80)
        
        summary = []
        summary.append("="*80)
        summary.append("B√ÅO C√ÅO PH√ÇN T√çCH T·ªîNG H·ª¢P")
        summary.append(f"Ng√†y t·∫°o: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
        summary.append("="*80)
        
        summary.append("\nüìä C√ÅC PH√ÇN T√çCH ƒê√É TH·ª∞C HI·ªÜN:")
        for i, analysis in enumerate(self.analysis_history, 1):
            summary.append(f"   {i}. {analysis}")
        
        if self.insights:
            summary.append("\nüí° C√ÅC INSIGHTS QUAN TR·ªåNG:")
            for i, insight in enumerate(self.insights, 1):
                summary.append(f"   {i}. {insight}")
        
        if self.visualizations:
            summary.append("\nüìà C√ÅC BI·ªÇU ƒê·ªí ƒê√É T·∫†O:")
            for i, viz in enumerate(self.visualizations, 1):
                summary.append(f"   {i}. {viz}")
        
        # Th√™m file m√¥ t·∫£ bi·∫øn v√†o summary
        var_desc_file = f'{self.output_dir}/variable_descriptions.txt'
        if os.path.exists(var_desc_file):
            summary.append("\nüìù File m√¥ t·∫£ bi·∫øn:")
            summary.append(f"   - {var_desc_file}")
        
        summary.append("\n" + "="*80)
        summary.append("K·∫æT TH√öC B√ÅO C√ÅO")
        summary.append("="*80)
        
        # L∆∞u summary
        filename = f'{self.output_dir}/00_summary_report.txt'
        with open(filename, 'w', encoding='utf-8') as f:
            f.write('\n'.join(summary))
        
        print("\n".join(summary))
        print(f"\n‚úì ƒê√£ l∆∞u b√°o c√°o t·ªïng h·ª£p: {filename}")
        
        return filename
    
    def run_all_analysis(self):
        """Ch·∫°y t·∫•t c·∫£ c√°c ph√¢n t√≠ch - Chu·∫©n h√≥a PH·∫¢I ch·∫°y tr∆∞·ªõc"""
        print("\n" + "="*80)
        print("CH·∫†Y T·∫§T C·∫¢ PH√ÇN T√çCH")
        print("="*80)
        print("\n‚ö† L∆∞u √Ω: Chu·∫©n h√≥a d·ªØ li·ªáu s·∫Ω ch·∫°y TR∆Ø·ªöC")
        
        # Normalize data first
        self.normalize_data()
        
        # Then run all analyses
        self.descriptive_statistics()
        self.estimation_hypothesis_testing()
        self.correlation_analysis()
        self.anova_analysis()
        self.regression_analysis()
        
        # NEW: T√¨m insights v√† t·∫°o visualizations
        self.find_insights()
        self.create_visualizations()
        
        # L∆∞u outputs
        self.save_terminal_output()
        self.create_summary_report()
        
        print("\n" + "="*80)
        print("‚úì ƒê√É HO√ÄN TH√ÄNH T·∫§T C·∫¢ PH√ÇN T√çCH!")
        print("="*80)
        print(f"\nK·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u trong th∆∞ m·ª•c: {self.output_dir}/")
        print(f"   - {len(self.visualizations)} bi·ªÉu ƒë·ªì")
        print(f"   - {len(self.insights)} insights")
        print(f"   - B√°o c√°o chi ti·∫øt")

    def _save_txt(self, filename):
        """L∆∞u b√°o c√°o d·∫°ng TXT"""
        if not filename.endswith('.txt'):
            filename = filename.replace('.docx', '').replace('.pdf', '') + '.txt'
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write('\n'.join(self.report))
            print(f"\n‚úì ƒê√£ l∆∞u b√°o c√°o TXT v√†o: {filename}")
        except Exception as e:
            print(f"‚úó L·ªói khi l∆∞u file TXT: {e}")
    
    def _save_docx(self, filename):
        """L∆∞u b√°o c√°o d·∫°ng DOCX"""
        if not DOCX_AVAILABLE:
            print("‚úó Ch∆∞a c√†i ƒë·∫∑t python-docx. Ch·∫°y l·ªánh: pip install python-docx")
            return
        
        if not filename.endswith('.docx'):
            filename = filename.replace('.txt', '').replace('.pdf', '') + '.docx'
        
        try:
            doc = Document()
            
            # Add title
            title = doc.add_heading('B√ÅO C√ÅO PH√ÇN T√çCH MARKETING NG√ÇN H√ÄNG', 0)
            title.alignment = 1
            
            # Add timestamp
            timestamp = doc.add_paragraph(f"T·∫°o l√∫c: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
            timestamp.alignment = 1
            
            doc.add_paragraph()
            
            # Add content
            for line in self.report:
                if line.startswith('='):
                    heading = doc.add_heading(line.strip('=').strip(), level=1)
                    heading.alignment = 1
                elif any(line.startswith(x) for x in ['A)', 'B)', 'C)', 'D)', 'E)']):
                    section = doc.add_heading(line, level=2)
                    section.runs[0].font.size = Pt(12)
                elif line.startswith('   '):
                    doc.add_paragraph(line, style='List Bullet')
                else:
                    doc.add_paragraph(line)
            
            doc.save(filename)
            print(f"\n‚úì ƒê√£ l∆∞u b√°o c√°o DOCX v√†o: {filename}")
        except Exception as e:
            print(f"‚úó L·ªói khi l∆∞u file DOCX: {e}")
    
    def _save_pdf(self, filename):
        """L∆∞u b√°o c√°o d·∫°ng PDF"""
        if not PDF_AVAILABLE:
            print("‚úó Ch∆∞a c√†i ƒë·∫∑t reportlab. Ch·∫°y l·ªánh: pip install reportlab")
            return
        
        if not filename.endswith('.pdf'):
            filename = filename.replace('.txt', '').replace('.docx', '') + '.pdf'
        
        try:
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
            
            pdf = SimpleDocTemplate(filename, pagesize=letter,
                                  rightMargin=0.5*inch, leftMargin=0.5*inch,
                                  topMargin=0.5*inch, bottomMargin=0.5*inch)
            
            story = []
            styles = getSampleStyleSheet()
            
            title_style = ParagraphStyle(
                'CustomTitle',
                parent=styles['Heading1'],
                fontSize=16,
                spaceAfter=30,
                alignment=TA_CENTER
            )
            
            heading_style = ParagraphStyle(
                'CustomHeading',
                parent=styles['Heading2'],
                fontSize=12,
                spaceAfter=12,
                spaceBefore=12,
                alignment=TA_LEFT
            )
            
            title = Paragraph("B√ÅO C√ÅO PH√ÇN T√çCH MARKETING NG√ÇN H√ÄNG", title_style)
            story.append(title)
            
            timestamp_text = f"T·∫°o l√∫c: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}"
            timestamp = Paragraph(timestamp_text, styles['Normal'])
            story.append(timestamp)
            story.append(Spacer(1, 0.3*inch))
            
            for line in self.report:
                if line.strip() == '':
                    story.append(Spacer(1, 0.1*inch))
                elif line.startswith('='):
                    heading = Paragraph(line.strip('=').strip(), heading_style)
                    story.append(heading)
                else:
                    line_safe = line.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                    p = Paragraph(line_safe, styles['Normal'])
                    story.append(p)
            
            pdf.build(story)
            print(f"\n‚úì ƒê√£ l∆∞u b√°o c√°o PDF v√†o: {filename}")
        except Exception as e:
            print(f"‚úó L·ªói khi l∆∞u file PDF: {e}")
    
    def _export_menu(self):
        """Hi·ªÉn th·ªã menu xu·∫•t file"""
        self.display_analysis_summary()
        
        print("\n" + "="*80)
        print("XU·∫§T K·∫æT QU·∫¢ PH√ÇN T√çCH")
        print("="*80)
        print("Ch·ªçn ƒë·ªãnh d·∫°ng xu·∫•t file:")
        print("1. TXT (T·ªáp vƒÉn b·∫£n)")
        print("2. DOCX (T√†i li·ªáu Word)")
        print("3. PDF (ƒê·ªãnh d·∫°ng PDF)")
        print("4. T·∫•t c·∫£ ƒë·ªãnh d·∫°ng (Xu·∫•t t·∫•t c·∫£ 3 lo·∫°i)")
        print("0. Quay l·∫°i menu ch√≠nh")
        
        choice = input("\nNh·∫≠p l·ª±a ch·ªçn (0-4): ").strip()
        
        base_filename = 'bank_analysis_report'
        
        if choice == '1':
            self.save_report(f"{base_filename}.txt", 'txt')
        elif choice == '2':
            self.save_report(f"{base_filename}.docx", 'docx')
        elif choice == '3':
            self.save_report(f"{base_filename}.pdf", 'pdf')
        elif choice == '4':
            print("\nƒêang xu·∫•t sang t·∫•t c·∫£ c√°c ƒë·ªãnh d·∫°ng...")
            self.save_report(f"{base_filename}.txt", 'txt')
            self.save_report(f"{base_filename}.docx", 'docx')
            self.save_report(f"{base_filename}.pdf", 'pdf')
            print("\n‚úì T·∫•t c·∫£ b√°o c√°o ƒë√£ ƒë∆∞·ª£c xu·∫•t th√†nh c√¥ng!")
        elif choice == '0':
            pass
        else:
            print(f"ƒê·ªãnh d·∫°ng kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {file_format}")
            print("C√°c ƒë·ªãnh d·∫°ng ƒë∆∞·ª£c h·ªó tr·ª£: txt, docx, pdf")
    
    def display_analysis_summary(self):
        """Hi·ªÉn th·ªã t√≥m t·∫Øt c√°c ph√¢n t√≠ch ƒë√£ ho√†n th√†nh"""
        print("\n" + "="*80)
        print("T√ìM T·∫ÆT PH√ÇN T√çCH ƒê√É HO√ÄN TH√ÄNH")
        print("="*80)
        print(f"\nT·ªïng s·ªë ph√¢n t√≠ch ƒë√£ ch·∫°y: {len(self.analysis_history)}")
        print("\nC√°c ph√¢n t√≠ch ƒë√£ ho√†n th√†nh:")
        for i, analysis in enumerate(self.analysis_history, 1):
            print(f"   {i}. {analysis}")
        print("\n" + "="*80)
    
    def save_report(self, filename='bank_analysis_report.txt', file_format='txt'):
        """L∆∞u b√°o c√°o v√†o file theo ƒë·ªãnh d·∫°ng ch·ªâ ƒë·ªãnh (txt, docx, pdf)"""
        file_format = file_format.lower()
        
        if file_format == 'txt':
            self._save_txt(filename)
        elif file_format == 'docx':
            self._save_docx(filename)
        elif file_format == 'pdf':
            self._save_pdf(filename)
        else:
            print(f"ƒê·ªãnh d·∫°ng kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {file_format}")
            print("C√°c ƒë·ªãnh d·∫°ng ƒë∆∞·ª£c h·ªó tr·ª£: txt, docx, pdf")
    
    def display_menu(self):
        """Hi·ªÉn th·ªã menu t∆∞∆°ng t√°c"""
        # Check if normalization has been done
        is_normalized = hasattr(self, 'df_normalized')
        
        while True:
            print("\n" + "="*80)
            print("H·ªÜ TH·ªêNG PH√ÇN T√çCH TH·ªêNG K√ä MARKETING NG√ÇN H√ÄNG")
            print("="*80)
            
            # Show normalization status
            norm_status = "‚úì ƒê√É CHU·∫®N H√ìA" if is_normalized else "‚ö† CH∆ØA CHU·∫®N H√ìA"
            print(f"\nTr·∫°ng th√°i chu·∫©n h√≥a: {norm_status}")
            
            print("\nCh·ªçn ph√¢n t√≠ch c·∫ßn th·ª±c hi·ªán:")
            print("0. Chu·∫©n H√≥a D·ªØ Li·ªáu - Chu·∫©n h√≥a c√°c bi·∫øn s·ªë")
            print("1. Th·ªëng K√™ M√¥ T·∫£ - Th√¥ng tin c∆° b·∫£n v·ªÅ d·ªØ li·ªáu")
            print("2. ∆Ø·ªõc L∆∞·ª£ng & Ki·ªÉm ƒê·ªãnh - Kho·∫£ng tin c·∫≠y v√† ki·ªÉm ƒë·ªãnh")
            print("3. Ph√¢n T√≠ch T∆∞∆°ng Quan - M·ªëi quan h·ªá gi·ªØa c√°c bi·∫øn")
            print("4. Ph√¢n T√≠ch ANOVA - So s√°nh trung b√¨nh nh√≥m")
            print("5. Ph√¢n T√≠ch H·ªìi Quy - M√¥ h√¨nh d·ª± ƒëo√°n")
            print("6. T·ª± ƒê·ªông T√¨m Insights - Ph√°t hi·ªán patterns quan tr·ªçng")
            print("7. T·∫°o Tr·ª±c Quan H√≥a - T·∫°o t·∫•t c·∫£ bi·ªÉu ƒë·ªì")
            print("8. Ch·∫°y T·∫•t C·∫£ Ph√¢n T√≠ch - Th·ª±c hi·ªán to√†n b·ªô (bao g·ªìm chu·∫©n h√≥a, insights, visualizations)")
            print("9. Xu·∫•t K·∫øt Qu·∫£ - L∆∞u b√°o c√°o")
            print("10. Tho√°t - K·∫øt th√∫c ch∆∞∆°ng tr√¨nh")
            
            choice = input("\nNh·∫≠p l·ª±a ch·ªçn (0-10): ").strip()
            
            if choice == '0':
                self.normalize_data()
                is_normalized = True
                input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
            elif choice == '1':
                if not is_normalized:
                    print("\n‚ö† L·ªñI: B·∫°n ph·∫£i chu·∫©n h√≥a d·ªØ li·ªáu tr∆∞·ªõc!")
                    print("   Vui l√≤ng ch·ªçn m·ª•c 0")
                    input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
                    continue
                self.descriptive_statistics()
                input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
            elif choice == '2':
                if not is_normalized:
                    print("\n‚ö† L·ªñI: B·∫°n ph·∫£i chu·∫©n h√≥a d·ªØ li·ªáu tr∆∞·ªõc!")
                    print("   Vui l√≤ng ch·ªçn m·ª•c 0")
                    input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
                    continue
                self.estimation_hypothesis_testing()
                input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
            elif choice == '3':
                if not is_normalized:
                    print("\n‚ö† L·ªñI: B·∫°n ph·∫£i chu·∫©n h√≥a d·ªØ li·ªáu tr∆∞·ªõc!")
                    print("   Vui l√≤ng ch·ªçn m·ª•c 0")
                    input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
                    continue
                self.correlation_analysis()
                input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
            elif choice == '4':
                if not is_normalized:
                    print("\n‚ö† L·ªñI: B·∫°n ph·∫£i chu·∫©n h√≥a d·ªØ li·ªáu tr∆∞·ªõc!")
                    print("   Vui l√≤ng ch·ªçn m·ª•c 0")
                    input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
                    continue
                self.anova_analysis()
                input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
            elif choice == '5':
                if not is_normalized:
                    print("\n‚ö† L·ªñI: B·∫°n ph·∫£i chu·∫©n h√≥a d·ªØ li·ªáu tr∆∞·ªõc!")
                    print("   Vui l√≤ng ch·ªçn m·ª•c 0")
                    input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
                    continue
                self.regression_analysis()
                input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
            elif choice == '6':
                if not is_normalized:
                    print("\n‚ö† L·ªñI: B·∫°n ph·∫£i chu·∫©n h√≥a d·ªØ li·ªáu tr∆∞·ªõc!")
                    print("   Vui l√≤ng ch·ªçn m·ª•c 0")
                    input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
                    continue
                self.find_insights()
                input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
            elif choice == '7':
                if not is_normalized:
                    print("\n‚ö† L·ªñI: B·∫°n ph·∫£i chu·∫©n h√≥a d·ªØ li·ªáu tr∆∞·ªõc!")
                    print("   Vui l√≤ng ch·ªçn m·ª•c 0")
                    input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
                    continue
                self.create_visualizations()
                input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
            elif choice == '8':
                print("\nCh·∫°y t·∫•t c·∫£ c√°c ph√¢n t√≠ch...")
                self.run_all_analysis()
                is_normalized = True
                input("\nNh·∫•n Enter ƒë·ªÉ ti·∫øp t·ª•c...")
            elif choice == '9':
                self._export_menu()
            elif choice == '10':
                print("\nC·∫£m ∆°n ƒë√£ s·ª≠ d·ª•ng h·ªá th·ªëng ph√¢n t√≠ch!")
                break
            else:
                print("\nL·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá. Vui l√≤ng th·ª≠ l·∫°i!")

def main():
    """H√†m ch√≠nh"""
    filepath = 'bank.csv'
    
    try:
        analysis = BankMarketingAnalysis(filepath)
        analysis.display_menu()
    except FileNotFoundError:
        print(f"L·ªói: Kh√¥ng t√¨m th·∫•y file: {filepath}")
    except Exception as e:
        print(f"L·ªói: {e}")

if __name__ == "__main__":
    main()
